{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pattern Recognition and Machine Learning\n",
                "## Week 4 Tutorial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3 Diabetes Data Analysis\n",
                "### 3.1 Import and Loading dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load dataset\n",
                "diabete_dataset = pd.read_csv(\"data/diabetes.csv\", sep=\",\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabete_dataset.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabete_dataset.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Explore the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabete_dataset.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Further analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabete_dataset.corr()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sn\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "sn.heatmap(diabete_dataset.corr(), annot=True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4 Diabetes Classification from Logistic Regression\n",
                "### 4.1 Feature extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract features and a target\n",
                "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
                "                   'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
                "\n",
                "X = diabete_dataset[feature_columns] # features\n",
                "y = diabete_dataset['Outcome'] # target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Feature: \" + str(X.shape))\n",
                "print(\"Target: \" + str(y.shape))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Splitting the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# split X and y into training and testing datasets\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
                "                                               test_size=0.25,\n",
                "                                               random_state=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Build a Logistic Regression model and make a prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "lgr = LogisticRegression(C = 10, max_iter=5000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lgr.fit(X_train, y_train)\n",
                "\n",
                "result = lgr.predict(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Model Evalation using Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import metrics\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "conf_matrix = metrics.confusion_matrix(y_test, result)\n",
                "print(conf_matrix)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Accuracy:\",metrics.accuracy_score(y_test, result))\n",
                "print(\"Precision:\",metrics.precision_score(y_test, result,\n",
                "                                           average = 'weighted'))\n",
                "print(\"Recall:\",metrics.recall_score(y_test, result,\n",
                "                                     average = 'weighted'))\n",
                "print(\"F1-score:\",metrics.f1_score(y_test, result,\n",
                "                                   average = 'weighted'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 ROC Curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fpr, tpr, _ = metrics.roc_curve(y_test, result)\n",
                "auc = metrics.roc_auc_score(y_test, result)\n",
                "\n",
                "auc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(fpr, tpr, label=\"auc=\" + str(auc))\n",
                "plt.title(\"ROC curve for Diabetes classifier\")\n",
                "plt.xlabel(\"False positive rate (1-Specificity)\")\n",
                "plt.ylabel(\"True positive rate (Sensitivity)\")\n",
                "plt.legend(loc=4)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display Misclassified rows with Predicted Labels\n",
                "index = 0\n",
                "misclassifiedIndexes = []\n",
                "for label, predict in zip(y_test, result):\n",
                "    if label != predict: \n",
                "        misclassifiedIndexes.append(index)\n",
                "    index +=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "np.array(misclassifiedIndexes).T"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.6 Find C to maximum the F1-score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def linear_regression(c):\n",
                "    lgr = LogisticRegression(C = c, max_iter=5000)\n",
                "    fit_lgr = lgr.fit(X_train, y_train)\n",
                "    predicted_lgr = fit_lgr.predict(X_test)\n",
                "    cm_lgr = metrics.confusion_matrix(y_test, predicted_lgr)\n",
                "    \n",
                "    f1_sc = metrics.f1_score(y_test, predicted_lgr, average = 'weighted')\n",
                "    return f1_sc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "c = 0.0001\n",
                "c_values = []\n",
                "f1_values = []\n",
                "\n",
                "while c < 1000:\n",
                "    f1_sc = linear_regression(c)\n",
                "    c_values.append(c)\n",
                "    f1_values.append(f1_sc)\n",
                "    c = c*10\n",
                "\n",
                "f1_lgr = pd.DataFrame({\n",
                "    \"c\": c_values,\n",
                "    \"f1\": f1_values\n",
                "})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f1_lgr[f1_lgr['f1'] == f1_lgr['f1'].max()].c"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f1_lgr.sort_values('f1', ascending=False)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
