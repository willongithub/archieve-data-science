{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Pattern Recognition and Machine Learning\r\n",
                "## Week 4 Tutorial"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3 Diabetes Data Analysis\r\n",
                "### 3.1 Import and Loading dataset"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# load dataset\r\n",
                "diabete_dataset = pd.read_csv(\"data/diabetes.csv\", sep=\",\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "diabete_dataset.head(10)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "diabete_dataset.shape"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 3.2 Explore the data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "diabete_dataset.info()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 3.3 Further analysis"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "diabete_dataset.corr()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import seaborn as sn\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "sn.heatmap(diabete_dataset.corr(), annot=True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4 Diabetes Classification from Logistic Regression\r\n",
                "### 4.1 Feature extraction"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Extract features and a target\r\n",
                "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\r\n",
                "                   'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\r\n",
                "\r\n",
                "X = diabete_dataset[feature_columns] # features\r\n",
                "y = diabete_dataset['Outcome'] # target"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(\"Feature: \" + str(X.shape))\r\n",
                "print(\"Target: \" + str(y.shape))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4.1 Splitting the dataset"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# split X and y into training and testing datasets\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "\r\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y,\r\n",
                "                                               test_size=0.25,\r\n",
                "                                               random_state=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "X_train.shape"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4.3 Build a Logistic Regression model and make a prediction"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.linear_model import LogisticRegression\r\n",
                "\r\n",
                "lgr = LogisticRegression(C = 10, max_iter=5000)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "lgr.fit(X_train, y_train)\r\n",
                "\r\n",
                "result = lgr.predict(X_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4.4 Model Evalation using Confusion Matrix"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn import metrics\r\n",
                "from sklearn.metrics import classification_report\r\n",
                "\r\n",
                "conf_matrix = metrics.confusion_matrix(y_test, result)\r\n",
                "print(conf_matrix)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(\"Accuracy:\",metrics.accuracy_score(y_test, result))\r\n",
                "print(\"Precision:\",metrics.precision_score(y_test, result,\r\n",
                "                                           average = 'weighted'))\r\n",
                "print(\"Recall:\",metrics.recall_score(y_test, result,\r\n",
                "                                     average = 'weighted'))\r\n",
                "print(\"F1-score:\",metrics.f1_score(y_test, result,\r\n",
                "                                   average = 'weighted'))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4.5 ROC Curve"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "fpr, tpr, _ = metrics.roc_curve(y_test, result)\r\n",
                "auc = metrics.roc_auc_score(y_test, result)\r\n",
                "\r\n",
                "auc"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.plot(fpr, tpr, label=\"auc=\" + str(auc))\r\n",
                "plt.title(\"ROC curve for Diabetes classifier\")\r\n",
                "plt.xlabel(\"False positive rate (1-Specificity)\")\r\n",
                "plt.ylabel(\"True positive rate (Sensitivity)\")\r\n",
                "plt.legend(loc=4)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "# Display Misclassified rows with Predicted Labels\r\n",
                "index = 0\r\n",
                "misclassifiedIndexes = []\r\n",
                "for label, predict in zip(y_test, result):\r\n",
                "    if label != predict: \r\n",
                "        misclassifiedIndexes.append(index)\r\n",
                "    index +=1"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import numpy as np\r\n",
                "\r\n",
                "np.array(misclassifiedIndexes).T"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4.6 Find C to maximum the F1-score"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def linear_regression(c):\r\n",
                "    lgr = LogisticRegression(C = c, max_iter=5000)\r\n",
                "    fit_lgr = lgr.fit(X_train, y_train)\r\n",
                "    predicted_lgr = fit_lgr.predict(X_test)\r\n",
                "    cm_lgr = metrics.confusion_matrix(y_test, predicted_lgr)\r\n",
                "    \r\n",
                "    f1_sc = metrics.f1_score(y_test, predicted_lgr, average = 'weighted')\r\n",
                "    return f1_sc"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "c = 0.0001\r\n",
                "c_values = []\r\n",
                "f1_values = []\r\n",
                "\r\n",
                "while c < 1000:\r\n",
                "    f1_sc = linear_regression(c)\r\n",
                "    c_values.append(c)\r\n",
                "    f1_values.append(f1_sc)\r\n",
                "    c = c*10\r\n",
                "\r\n",
                "f1_lgr = pd.DataFrame({\r\n",
                "    \"c\": c_values,\r\n",
                "    \"f1\": f1_values\r\n",
                "})"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "f1_lgr[f1_lgr['f1'] == f1_lgr['f1'].max()].c"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "f1_lgr.sort_values('f1', ascending=False)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}